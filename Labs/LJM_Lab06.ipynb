{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LJM_Lab06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9122984537704be69003aa5fc7e0311b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8d8bbc237f7b4768b5630830cf7795c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c94d85ac53a54dd786659e137a8f786b",
              "IPY_MODEL_630dcd1a83a14083ab3b4949238c5ba9",
              "IPY_MODEL_0c8cf816c94a4f0f91d256d08732c2f8"
            ]
          }
        },
        "8d8bbc237f7b4768b5630830cf7795c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c94d85ac53a54dd786659e137a8f786b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdb3381eab9b4ce1b8e670da21089d35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df87b8725db44bfeb391ac4a092eeddd"
          }
        },
        "630dcd1a83a14083ab3b4949238c5ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ba971c4c1b1438ba0be4507c33d330c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c15f15289b444ec0b45f7b9d31e5b3ef"
          }
        },
        "0c8cf816c94a4f0f91d256d08732c2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8af1b1e6b15415f9097aae513906396",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 51279468.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a6953c7be4d474daa6b152035f45652"
          }
        },
        "bdb3381eab9b4ce1b8e670da21089d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df87b8725db44bfeb391ac4a092eeddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ba971c4c1b1438ba0be4507c33d330c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c15f15289b444ec0b45f7b9d31e5b3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8af1b1e6b15415f9097aae513906396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a6953c7be4d474daa6b152035f45652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morcellinus/Introduction_to_Deep_Learning/blob/main/LJM_Lab06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3dotnhNCKsl"
      },
      "source": [
        "## Lab 6 (Image Processing using Convolutional Neural Networks)\n",
        "- CIFAR10 dataset (see https://www.cs.toronto.edu/~kriz/cifar.html for more info)\n",
        "- 60K images: 50K train, 10K test\n",
        "- 10 classes: 'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "- Perform multi-class classification with evaluation accuracy on EACH class\n",
        "\n",
        "**CONNECT TO GPU** before continuing, but just CPU is also fine, it might be a bit slow.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ8bPH1OCM5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "9122984537704be69003aa5fc7e0311b",
            "8d8bbc237f7b4768b5630830cf7795c0",
            "c94d85ac53a54dd786659e137a8f786b",
            "630dcd1a83a14083ab3b4949238c5ba9",
            "0c8cf816c94a4f0f91d256d08732c2f8",
            "bdb3381eab9b4ce1b8e670da21089d35",
            "df87b8725db44bfeb391ac4a092eeddd",
            "4ba971c4c1b1438ba0be4507c33d330c",
            "c15f15289b444ec0b45f7b9d31e5b3ef",
            "e8af1b1e6b15415f9097aae513906396",
            "3a6953c7be4d474daa6b152035f45652"
          ]
        },
        "outputId": "d399570a-7ad7-4bd1-a3b3-f1c825a7d71d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Download and prepare dataset\n",
        "# Transform them to tensors and normalise them\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "# 2.2 Download data\n",
        "train_set = torchvision.datasets.CIFAR10(\"./\", train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(\"./\", train=False, download=True, transform=transform)\n",
        "\n",
        "# 2.3 Use DataLoader to get batches and shuffle\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Q1. Why are there 3 values in each list of the Normalize() function? What do they represent?\n",
        "print('There are 3 values in each list of the Normalize() since the data we have is about colored image. Color Image has three channels. First list represents the mean of the channel and the second represents the channel standard deviation.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9122984537704be69003aa5fc7e0311b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n",
            "There are 3 values in each list of the Normalize() since the data we have is about colored image. Color Image has three channels. First list represents the mean of the channel and the second represents the channel standard deviation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuhDiijV7CNT"
      },
      "source": [
        "### Inspect the Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "032BETSy6a2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb28be9-8064-4389-b4d5-f0e25b7b5220"
      },
      "source": [
        "# Access the first data sample in the train_set using next(iter())\n",
        "batch = next(iter(train_loader))\n",
        "print(f'Image values: \\n{batch}')\n",
        "print(f'Length: {len(batch)}')\n",
        "print(f'Type: {type(batch)}')\n",
        "\n",
        "# This means the data contains image-label pairs\n",
        "# Unpack them\n",
        "images, labels = batch\n",
        "# Same as these two lines:\n",
        "# image = batch[0]\n",
        "# label = batch[1]\n",
        "\n",
        "\n",
        "print(images.shape)\n",
        "print(labels)\n",
        "\n",
        "# Q2. What is the range of the values for the normalised image pixels?\n",
        "print('\\nThe range of the values for the normalised image pixels will be between -1 to 1')\n",
        "# Q3. What does each index value of the shape of the image represent?\n",
        "print('\\nFirst Index: Batch Size \\nSecond Index: Channels \\nThird Index: Height of the image \\nLast Index: Width of the image')\n",
        "# Q4. What do the label values represent?\n",
        "print('\\nLabel values represent the labels(dependent variable of this dataset) of the first data sample in the train_set')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image values: \n",
            "[tensor([[[[-0.8510, -0.8745, -0.7804,  ...,  0.9529,  0.9843,  0.9922],\n",
            "          [-0.9451, -0.9059, -0.8588,  ...,  0.8118,  0.8980,  0.9843],\n",
            "          [-0.8980, -0.6706, -0.6314,  ...,  0.7098,  0.7333,  0.8275],\n",
            "          ...,\n",
            "          [-0.6392, -0.6627, -0.6627,  ..., -0.6314, -0.6000, -0.5843],\n",
            "          [-0.6627, -0.6235, -0.6000,  ..., -0.6549, -0.6235, -0.5843],\n",
            "          [-0.6157, -0.6000, -0.6549,  ..., -0.6235, -0.6235, -0.6392]],\n",
            "\n",
            "         [[-0.4353, -0.4667, -0.2784,  ...,  0.9922,  1.0000,  1.0000],\n",
            "          [-0.6471, -0.6863, -0.5608,  ...,  0.9137,  0.9765,  1.0000],\n",
            "          [-0.6314, -0.2863, -0.2784,  ...,  0.8431,  0.8745,  0.9373],\n",
            "          ...,\n",
            "          [-0.4510, -0.4824, -0.4902,  ..., -0.4431, -0.3961, -0.3804],\n",
            "          [-0.4745, -0.4431, -0.4118,  ..., -0.4745, -0.4118, -0.3725],\n",
            "          [-0.4275, -0.3961, -0.4353,  ..., -0.4510, -0.4275, -0.4196]],\n",
            "\n",
            "         [[-0.2235, -0.2157, -0.0510,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.4275, -0.4667, -0.3647,  ...,  0.9373,  0.9843,  1.0000],\n",
            "          [-0.4196, -0.0980, -0.0588,  ...,  0.8745,  0.8902,  0.9451],\n",
            "          ...,\n",
            "          [-0.7882, -0.8118, -0.8118,  ..., -0.8118, -0.7647, -0.7569],\n",
            "          [-0.8118, -0.7804, -0.7412,  ..., -0.8196, -0.7804, -0.7490],\n",
            "          [-0.7882, -0.7569, -0.8039,  ..., -0.7804, -0.7882, -0.7882]]],\n",
            "\n",
            "\n",
            "        [[[-0.0588,  0.4275,  0.5059,  ...,  0.5137,  0.4745,  0.3255],\n",
            "          [-0.4039,  0.2314,  0.3490,  ...,  0.3412,  0.2706,  0.0745],\n",
            "          [-0.4275,  0.2549,  0.3882,  ...,  0.3647,  0.2863,  0.0902],\n",
            "          ...,\n",
            "          [-0.4196, -0.5686, -0.6000,  ..., -0.0980, -0.1059, -0.3020],\n",
            "          [-0.4196, -0.5608, -0.6314,  ..., -0.1686, -0.1765, -0.2627],\n",
            "          [-0.2941, -0.4039, -0.4431,  ..., -0.1137, -0.1137, -0.1451]],\n",
            "\n",
            "         [[-0.1216,  0.3255,  0.4275,  ...,  0.4431,  0.3725,  0.2471],\n",
            "          [-0.4667,  0.1294,  0.2784,  ...,  0.2706,  0.1765, -0.0039],\n",
            "          [-0.4902,  0.1529,  0.3176,  ...,  0.2863,  0.1843,  0.0118],\n",
            "          ...,\n",
            "          [-0.6078, -0.7804, -0.7961,  ..., -0.3647, -0.3804, -0.5216],\n",
            "          [-0.6000, -0.7804, -0.8196,  ..., -0.4039, -0.4275, -0.4745],\n",
            "          [-0.4353, -0.5765, -0.5922,  ..., -0.2784, -0.3020, -0.3098]],\n",
            "\n",
            "         [[-0.0824,  0.3804,  0.4745,  ...,  0.4824,  0.4275,  0.2941],\n",
            "          [-0.4275,  0.1843,  0.3176,  ...,  0.3098,  0.2314,  0.0353],\n",
            "          [-0.4510,  0.2078,  0.3569,  ...,  0.3333,  0.2392,  0.0588],\n",
            "          ...,\n",
            "          [-0.6549, -0.8588, -0.8588,  ..., -0.4980, -0.5216, -0.6157],\n",
            "          [-0.6627, -0.8745, -0.8980,  ..., -0.5216, -0.5529, -0.5765],\n",
            "          [-0.4902, -0.6627, -0.6627,  ..., -0.3569, -0.3961, -0.3961]]],\n",
            "\n",
            "\n",
            "        [[[-0.0902, -0.8510, -0.8588,  ..., -0.8588, -0.8667, -0.4196],\n",
            "          [-0.8039, -0.8902, -0.8510,  ..., -0.8510, -0.8667, -0.9373],\n",
            "          [-0.8980, -0.8667, -0.8588,  ..., -0.8667, -0.8588, -0.8824],\n",
            "          ...,\n",
            "          [ 0.3333,  0.3961,  0.4902,  ..., -0.8902, -0.8902, -0.8980],\n",
            "          [ 0.3961,  0.5137,  0.5451,  ..., -0.8824, -0.8824, -0.9451],\n",
            "          [ 0.6392,  0.5216,  0.4353,  ..., -0.8667, -0.8980, -0.6784]],\n",
            "\n",
            "         [[ 0.0118, -0.6627, -0.6471,  ..., -0.7098, -0.7020, -0.2706],\n",
            "          [-0.6235, -0.6941, -0.6627,  ..., -0.6863, -0.6627, -0.7412],\n",
            "          [-0.7255, -0.6784, -0.6784,  ..., -0.6863, -0.6706, -0.6941],\n",
            "          ...,\n",
            "          [ 0.3961,  0.4510,  0.5294,  ..., -0.7725, -0.7647, -0.7647],\n",
            "          [ 0.4431,  0.5608,  0.5765,  ..., -0.7569, -0.7647, -0.8275],\n",
            "          [ 0.6627,  0.5529,  0.5137,  ..., -0.7490, -0.7804, -0.6078]],\n",
            "\n",
            "         [[ 0.2157, -0.3412, -0.3725,  ..., -0.4510, -0.4431, -0.0902],\n",
            "          [-0.3647, -0.4118, -0.4039,  ..., -0.4275, -0.4196, -0.4902],\n",
            "          [-0.4510, -0.4275, -0.4118,  ..., -0.4353, -0.4353, -0.4353],\n",
            "          ...,\n",
            "          [ 0.5608,  0.6000,  0.6706,  ..., -0.5529, -0.5529, -0.5529],\n",
            "          [ 0.6000,  0.6941,  0.7255,  ..., -0.5216, -0.5294, -0.6157],\n",
            "          [ 0.7490,  0.6941,  0.6471,  ..., -0.5059, -0.5373, -0.4118]]],\n",
            "\n",
            "\n",
            "        [[[-0.3490, -0.2471, -0.3490,  ..., -0.7490, -0.7961, -0.8431],\n",
            "          [-0.3176, -0.3020, -0.3412,  ..., -0.3961, -0.5216, -0.5137],\n",
            "          [-0.1922, -0.0902, -0.0588,  ...,  0.3098,  0.2157,  0.1922],\n",
            "          ...,\n",
            "          [ 0.7020,  0.5843,  0.0275,  ...,  0.0745,  0.0980,  0.0902],\n",
            "          [ 0.4745,  0.5059, -0.0980,  ...,  0.0431,  0.0667,  0.0510],\n",
            "          [ 0.4745,  0.4510, -0.1765,  ...,  0.0275,  0.0275, -0.0118]],\n",
            "\n",
            "         [[-0.2157, -0.1059, -0.2314,  ..., -0.7176, -0.7569, -0.8118],\n",
            "          [-0.0824, -0.0667, -0.1373,  ..., -0.3647, -0.4980, -0.4902],\n",
            "          [ 0.0431,  0.1451,  0.1451,  ...,  0.3176,  0.2314,  0.2078],\n",
            "          ...,\n",
            "          [ 0.6863,  0.5922,  0.0510,  ..., -0.0353, -0.0275, -0.0431],\n",
            "          [ 0.4588,  0.5137, -0.0745,  ..., -0.0667, -0.0667, -0.0667],\n",
            "          [ 0.4588,  0.4588, -0.1529,  ..., -0.0824, -0.0902, -0.1294]],\n",
            "\n",
            "         [[-0.0980, -0.0039, -0.1529,  ..., -0.6941, -0.7333, -0.7882],\n",
            "          [ 0.1373,  0.1373,  0.0275,  ..., -0.3490, -0.4745, -0.4745],\n",
            "          [ 0.2863,  0.3725,  0.3176,  ...,  0.3412,  0.2471,  0.2235],\n",
            "          ...,\n",
            "          [ 0.5765,  0.5294,  0.1294,  ..., -0.0353, -0.0196, -0.0275],\n",
            "          [ 0.3490,  0.4510,  0.0039,  ..., -0.0667, -0.0588, -0.0588],\n",
            "          [ 0.3490,  0.3961, -0.0745,  ..., -0.0824, -0.0902, -0.1216]]]]), tensor([1, 5, 8, 1])]\n",
            "Length: 2\n",
            "Type: <class 'list'>\n",
            "torch.Size([4, 3, 32, 32])\n",
            "tensor([1, 5, 8, 1])\n",
            "\n",
            "The range of the values for the normalised image pixels will be between -1 to 1\n",
            "\n",
            "First Index: Batch Size \n",
            "Second Index: Channels \n",
            "Third Index: Height of the image \n",
            "Last Index: Width of the image\n",
            "\n",
            "Label values represent the labels(dependent variable of this dataset) of the first data sample in the train_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71_0Ci7gZkqV"
      },
      "source": [
        "### View some images\n",
        "- Note that images have been normalised and may not look very clear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwz0kGvfuL6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "7552a787-6b6a-42b9-af05-db2c8a41d1d9"
      },
      "source": [
        "# Create a grid \n",
        "plt.figure(figsize=(12,12))\n",
        "grid = torchvision.utils.make_grid(tensor=images, nrow=4) # nrow = number of images displayed in each row\n",
        "\n",
        "print(f\"class labels: {labels}\")\n",
        "\n",
        "# Use grid.permute() to transpose the grid so that the axes meet the specifications required by \n",
        "# plt.imshow(), which are [height, width, channels]. PyTorch dimensions are [channels, height, width].\n",
        "plt.imshow(grid.permute(1,2,0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class labels: tensor([1, 5, 8, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f47d59d81d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVMti_g2J-W5"
      },
      "source": [
        "## CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWePXqBQKAp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f96089-daf8-4f2b-a013-2a3dbc8b5fb4"
      },
      "source": [
        "class Test(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # in / out / filter\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5, padding = 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "    # flatten 3D tensor to 1D tensor\n",
        "    # 32 filter 28 pool 14 filter 10 pool 5\n",
        "    self.fc1 = nn.Linear(16*5*5, 128) # Q8. Fill out the correct input dimensions \n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10) # final output matches num_classes\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Conv + ReLU + pool\n",
        "    print(f'Input shape: {x.shape}')\n",
        "    out = self.conv1(x)\n",
        "    print(f'After Conv1: {out.shape}')\n",
        "    print(f'Padding: {self.conv1.padding}')\n",
        "    out = self.pool(F.relu(out))\n",
        "    print(f'After Pool1: {out.shape}')\n",
        "    out = self.conv2(out)\n",
        "    print(f'After Conv2: {out.shape}')\n",
        "    out = self.pool(F.relu(out))\n",
        "    print(f'After Pool2: {out.shape}')\n",
        "    # Flatten it before fc1\n",
        "    out = out.reshape(-1, 16*5*5) # Q8. Fill out the correct dimension after -1\n",
        "    print(f'Before fc1: {out.shape}')\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu(out)\n",
        "    print(f'After fc1: {out.shape}')\n",
        "    out = self.fc2(out)\n",
        "    out = self.relu(out)\n",
        "    print(f'After fc2: {out.shape}')\n",
        "    out = self.fc3(out) # NO softmax as it will be included in CrossEntropyLoss\n",
        "    print(f'After fc3: {out.shape}')\n",
        "    return out\n",
        "\n",
        "\n",
        "model = Test().to(device)\n",
        "# Let's view the softmax output\n",
        "probs = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "# Q5. What do the three arguments of the first convolutional layer, conv1 represent (3,6,5)? \n",
        "print('\\nNumber of input channels (3 b/c it is color image), Number of output channels, and Filter size')\n",
        "# Q6. Explain the arguments of the second convolutional layer, conv2 (6, 16, 5) \n",
        "print('\\nNumber of input channels, (has to be 6 because the output channel of previous layer was 6), Number of output channels, and Filter size')\n",
        "# Q7. Figure out the convolved image size after conv1\n",
        "# Convolved image size = ((input_width - filter_size + 2 * padding) / stride) + 1\n",
        "print('\\n28')\n",
        "# Q8. Figure out the input size to the first fcn layer and fill out the code above in init() and forward()\n",
        "print('\\nshould be 16*5*5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of input channels (3 b/c it is color image), Number of output channels, and Filter size\n",
            "\n",
            "Number of input channels, (has to be 6 because the output channel of previous layer was 6), Number of output channels, and Filter size\n",
            "\n",
            "28\n",
            "\n",
            "should be 16*5*5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZk7fcriftFm"
      },
      "source": [
        "### Run through a sample batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW7t-qz-FjGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080bcee1-4e90-4481-cc03-1c925d3d8bdb"
      },
      "source": [
        "sample = next(iter(train_loader))\n",
        "\n",
        "images, labels = sample\n",
        "\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "output = model(images)\n",
        "print(f'Output shape: {output.shape}')\n",
        "print(f'Softmax outputs:\\n {probs(output)}')\n",
        "\n",
        "\n",
        "# Q9. Explain the shape of the output after conv1\n",
        "print('\\nShape of the output after conv1 should be 28*28. This is because the original shape is 32*32 and the filter size is 5. This remains 2 untouched pixels for each edge of the image')\n",
        "# Q10. What does the pooling do to the dimensions of the feature images here?\n",
        "print('\\nPooling halves the size of the output after conv1 layer')\n",
        "# Q11. Add padding=1 to conv1 and rerun the last two code cells. How did padding affect the dimensions of the feature images?\n",
        "print('\\nPadding enlarged the size of convolved image from 28 by 28 to 30 by 30 since padding enables us to get the pixel from the four edges of the image. 30 is derived by the equation [{(32 - 5 + 2)/1}+1] = 30')\n",
        "# Q12. What is represented by each list returned by Softmax outputs?\n",
        "print('\\nEach list returned by Softmax outputs shows the probability of each image to be classified as each label(y). For example, for the first list, the 8th value from the list is the largest. Therefore the first image in this batch should belong to 8th label.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 3, 32, 32])\n",
            "After Conv1: torch.Size([4, 6, 30, 30])\n",
            "Padding: (1, 1)\n",
            "After Pool1: torch.Size([4, 6, 15, 15])\n",
            "After Conv2: torch.Size([4, 16, 11, 11])\n",
            "After Pool2: torch.Size([4, 16, 5, 5])\n",
            "Before fc1: torch.Size([4, 400])\n",
            "After fc1: torch.Size([4, 128])\n",
            "After fc2: torch.Size([4, 64])\n",
            "After fc3: torch.Size([4, 10])\n",
            "Output shape: torch.Size([4, 10])\n",
            "Softmax outputs:\n",
            " tensor([[0.0903, 0.1026, 0.1043, 0.0911, 0.1032, 0.0956, 0.1078, 0.1096, 0.1057,\n",
            "         0.0899],\n",
            "        [0.0909, 0.1021, 0.1047, 0.0899, 0.1037, 0.0958, 0.1078, 0.1097, 0.1059,\n",
            "         0.0895],\n",
            "        [0.0921, 0.1024, 0.1034, 0.0924, 0.1020, 0.0909, 0.1098, 0.1103, 0.1058,\n",
            "         0.0910],\n",
            "        [0.0903, 0.1022, 0.1054, 0.0903, 0.1023, 0.0950, 0.1090, 0.1089, 0.1064,\n",
            "         0.0903]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "\n",
            "Shape of the output after conv1 should be 28*28. This is because the original shape is 32*32 and the filter size is 5. This remains 2 untouched pixels for each edge of the image\n",
            "\n",
            "Pooling halves the size of the output after conv1 layer\n",
            "\n",
            "Padding enlarged the size of convolved image from 28 by 28 to 30 by 30 since padding enables us to get the pixel from the four edges of the image. 30 is derived by the equation [{(32 - 5 + 2)/1}+1] = 30\n",
            "\n",
            "Each list returned by Softmax outputs shows the probability of each image to be classified as each label(y). For example, for the first list, the 8th value from the list is the largest. Therefore the first image in this batch should belong to 8th label.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQj3gsf7Y6Ql"
      },
      "source": [
        "\n",
        "### Let's Train!\n",
        "- Now that we know and understand how CNNs work, let's put everything together for CIFAR-10 dataset\n",
        "  - Download the data in batches and normalisation with shuffling\n",
        "  - Build a model with 2 CNN layers containing ReLU and pooling\n",
        "  - Passing the feature images to 3 fully connected layers (FCNs) also containing RELU activation\n",
        "  - The final layer has 10 units to reprsent the number of output classes\n",
        "  - Use Binary Cross Entropy Loss and SGD optimiser\n",
        "  - Evaluate the model on the test data on EACH class\n",
        "\n",
        "**IMPORTANT!** Fill out the missing code below before training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_4tKL4X3WQ"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    #self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "    # flatten 3D tensor to 1D tensor\n",
        "    self.fc1 = nn.Linear(16*5*5, 128) # TODO\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10) # final output matches num_classes\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Conv + ReLU + pool\n",
        "    out = self.pool(F.relu(self.conv1(x)))\n",
        "    out = self.pool(F.relu(self.conv2(out)))\n",
        "    # Flatten it before fc1\n",
        "    out = out.reshape(-1, 16*5*5) # TODO\n",
        "    out = F.relu(self.fc1(out))\n",
        "    out = F.relu(self.fc2(out))\n",
        "    out = self.fc3(out) # NO softmax as it will be included in CrossEntropyLoss\n",
        "    return out\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Q13. Use the Cross Entropy Loss for this task (UNCOMMENT & COMPLETE CODE BELOW)\n",
        "criterion = nn.CrossEntropyLoss() # will apply softmax\n",
        "\n",
        "# Q14. Use the Stochastic Gradient Descent (SGD) optimiser, this time ADD momentum=0.9 (UNCOMMENT & COMPLETE CODE BELOW)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlg2FFaJKppP"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e15E85ZQKr1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87348d00-bfb6-43f5-8a4d-b96ca8d1d7b8"
      },
      "source": [
        "n_total_steps = len(train_set)\n",
        "n_iterations = -(-n_total_steps // batch_size) # ceiling division\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    #print(images.shape) # [4,3,32,32] batch size, channels, img dim\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass and Optimise\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    # Print\n",
        "    if (i+1) % 1000 == 0:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, Iteration {i+1}/{n_iterations}, Loss={loss.item():.4f} ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4, Iteration 1000/12500, Loss=2.2901 \n",
            "Epoch 1/4, Iteration 2000/12500, Loss=1.6949 \n",
            "Epoch 1/4, Iteration 3000/12500, Loss=1.5985 \n",
            "Epoch 1/4, Iteration 4000/12500, Loss=1.1184 \n",
            "Epoch 1/4, Iteration 5000/12500, Loss=2.1383 \n",
            "Epoch 1/4, Iteration 6000/12500, Loss=1.1556 \n",
            "Epoch 1/4, Iteration 7000/12500, Loss=0.9093 \n",
            "Epoch 1/4, Iteration 8000/12500, Loss=1.0887 \n",
            "Epoch 1/4, Iteration 9000/12500, Loss=1.6856 \n",
            "Epoch 1/4, Iteration 10000/12500, Loss=2.3143 \n",
            "Epoch 1/4, Iteration 11000/12500, Loss=2.4090 \n",
            "Epoch 1/4, Iteration 12000/12500, Loss=1.4585 \n",
            "Epoch 2/4, Iteration 1000/12500, Loss=0.9875 \n",
            "Epoch 2/4, Iteration 2000/12500, Loss=0.9975 \n",
            "Epoch 2/4, Iteration 3000/12500, Loss=1.1968 \n",
            "Epoch 2/4, Iteration 4000/12500, Loss=0.8513 \n",
            "Epoch 2/4, Iteration 5000/12500, Loss=2.3219 \n",
            "Epoch 2/4, Iteration 6000/12500, Loss=0.6026 \n",
            "Epoch 2/4, Iteration 7000/12500, Loss=1.1051 \n",
            "Epoch 2/4, Iteration 8000/12500, Loss=1.7121 \n",
            "Epoch 2/4, Iteration 9000/12500, Loss=0.6904 \n",
            "Epoch 2/4, Iteration 10000/12500, Loss=0.9324 \n",
            "Epoch 2/4, Iteration 11000/12500, Loss=2.2510 \n",
            "Epoch 2/4, Iteration 12000/12500, Loss=1.1672 \n",
            "Epoch 3/4, Iteration 1000/12500, Loss=1.0314 \n",
            "Epoch 3/4, Iteration 2000/12500, Loss=3.4432 \n",
            "Epoch 3/4, Iteration 3000/12500, Loss=1.3901 \n",
            "Epoch 3/4, Iteration 4000/12500, Loss=0.2910 \n",
            "Epoch 3/4, Iteration 5000/12500, Loss=0.3928 \n",
            "Epoch 3/4, Iteration 6000/12500, Loss=1.8051 \n",
            "Epoch 3/4, Iteration 7000/12500, Loss=1.1289 \n",
            "Epoch 3/4, Iteration 8000/12500, Loss=1.1945 \n",
            "Epoch 3/4, Iteration 9000/12500, Loss=1.0378 \n",
            "Epoch 3/4, Iteration 10000/12500, Loss=1.9899 \n",
            "Epoch 3/4, Iteration 11000/12500, Loss=1.5034 \n",
            "Epoch 3/4, Iteration 12000/12500, Loss=1.3602 \n",
            "Epoch 4/4, Iteration 1000/12500, Loss=0.9253 \n",
            "Epoch 4/4, Iteration 2000/12500, Loss=1.3046 \n",
            "Epoch 4/4, Iteration 3000/12500, Loss=0.4877 \n",
            "Epoch 4/4, Iteration 4000/12500, Loss=1.8315 \n",
            "Epoch 4/4, Iteration 5000/12500, Loss=1.2254 \n",
            "Epoch 4/4, Iteration 6000/12500, Loss=0.7150 \n",
            "Epoch 4/4, Iteration 7000/12500, Loss=0.8260 \n",
            "Epoch 4/4, Iteration 8000/12500, Loss=1.1923 \n",
            "Epoch 4/4, Iteration 9000/12500, Loss=1.0856 \n",
            "Epoch 4/4, Iteration 10000/12500, Loss=1.3448 \n",
            "Epoch 4/4, Iteration 11000/12500, Loss=1.1423 \n",
            "Epoch 4/4, Iteration 12000/12500, Loss=1.1237 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HahXHRsSMo6H"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIuqYw8JMqy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aed32b2-f407-4249-f121-656357c705e5"
      },
      "source": [
        "# Deactivate the autograd engine to reduce memory usage and speed up computations (backprop disabled).\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "\n",
        "  # Loop through test set\n",
        "  for images, labels in test_loader:\n",
        "    # Put images on GPU\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # Run on trained model\n",
        "    outputs = model(images) \n",
        "\n",
        "    # Get predictions\n",
        "    # torch.max() returns actual probability value (ignored) and index or class label (selected)\n",
        "    _, y_preds = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0) # different to FFNN\n",
        "    n_correct += (y_preds == labels).sum().item()\n",
        "\n",
        "    # Keep track of each class\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = y_preds[i]\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  # Print accuracy\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Test Accuracy of the WHOLE CNN = {acc} %')\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the WHOLE CNN = 60.18 %\n",
            "Accuracy of plane: 66.4 %\n",
            "Accuracy of car: 65.2 %\n",
            "Accuracy of bird: 43.1 %\n",
            "Accuracy of cat: 45.7 %\n",
            "Accuracy of deer: 46.3 %\n",
            "Accuracy of dog: 45.3 %\n",
            "Accuracy of frog: 78.9 %\n",
            "Accuracy of horse: 64.7 %\n",
            "Accuracy of ship: 68.8 %\n",
            "Accuracy of truck: 77.4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TKj_ZV-Dzzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01c1d3c-6e4a-4cec-e043-0bc7a4c511c3"
      },
      "source": [
        "# Q15. Why don't we need to reshape the input images when training and testing?\n",
        "print('This is because the size of input image will shrink as going through convolution layers and pooling, and also before deriving output, we will flatten the image.')\n",
        "# Q16. Try to improve the model performance, e.g. by increasing the epochs, changing batch size, adding convolutions, etc.\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    #self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "    # flatten 3D tensor to 1D tensor\n",
        "    self.fc1 = nn.Linear(16*5*5, 128) \n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10) \n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    out = self.pool(F.relu(self.conv1(x)))\n",
        "    out = self.pool(F.relu(self.conv2(out)))\n",
        "    \n",
        "    out = out.reshape(-1, 16*5*5) \n",
        "    out = F.relu(self.fc1(out))\n",
        "    out = F.relu(self.fc2(out))\n",
        "    out = self.fc3(out) \n",
        "    return out\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n",
        "\n",
        "n_total_steps = len(train_set)\n",
        "n_iterations = -(-n_total_steps // batch_size) \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    \n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if (i+1) % 300 == 0:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, Iteration {i+1}/{n_iterations}, Loss={loss.item():.4f} ')\n",
        "\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "\n",
        "  # Loop through test set\n",
        "  for images, labels in test_loader:\n",
        "    # Put images on GPU\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # Run on trained model\n",
        "    outputs = model(images) \n",
        "\n",
        "    # Get predictions\n",
        "    # torch.max() returns actual probability value (ignored) and index or class label (selected)\n",
        "    _, y_preds = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0) # different to FFNN\n",
        "    n_correct += (y_preds == labels).sum().item()\n",
        "\n",
        "    # Keep track of each class\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = y_preds[i]\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  # Print accuracy\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Test Accuracy of the WHOLE CNN = {acc} %')\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is because the size of input image will shrink as going through convolution layers and pooling, and also before deriving output, we will flatten the image.\n",
            "Epoch 1/20, Iteration 300/3125, Loss=2.2945 \n",
            "Epoch 1/20, Iteration 600/3125, Loss=2.2903 \n",
            "Epoch 1/20, Iteration 900/3125, Loss=2.2685 \n",
            "Epoch 1/20, Iteration 1200/3125, Loss=2.1937 \n",
            "Epoch 1/20, Iteration 1500/3125, Loss=2.2482 \n",
            "Epoch 1/20, Iteration 1800/3125, Loss=1.9059 \n",
            "Epoch 1/20, Iteration 2100/3125, Loss=1.9809 \n",
            "Epoch 1/20, Iteration 2400/3125, Loss=1.6593 \n",
            "Epoch 1/20, Iteration 2700/3125, Loss=1.8339 \n",
            "Epoch 1/20, Iteration 3000/3125, Loss=1.7281 \n",
            "Epoch 2/20, Iteration 300/3125, Loss=1.6154 \n",
            "Epoch 2/20, Iteration 600/3125, Loss=1.8748 \n",
            "Epoch 2/20, Iteration 900/3125, Loss=1.3542 \n",
            "Epoch 2/20, Iteration 1200/3125, Loss=1.4577 \n",
            "Epoch 2/20, Iteration 1500/3125, Loss=1.5003 \n",
            "Epoch 2/20, Iteration 1800/3125, Loss=1.4770 \n",
            "Epoch 2/20, Iteration 2100/3125, Loss=1.5870 \n",
            "Epoch 2/20, Iteration 2400/3125, Loss=1.5934 \n",
            "Epoch 2/20, Iteration 2700/3125, Loss=1.0712 \n",
            "Epoch 2/20, Iteration 3000/3125, Loss=1.4006 \n",
            "Epoch 3/20, Iteration 300/3125, Loss=1.6857 \n",
            "Epoch 3/20, Iteration 600/3125, Loss=1.6585 \n",
            "Epoch 3/20, Iteration 900/3125, Loss=1.7553 \n",
            "Epoch 3/20, Iteration 1200/3125, Loss=1.2238 \n",
            "Epoch 3/20, Iteration 1500/3125, Loss=1.5451 \n",
            "Epoch 3/20, Iteration 1800/3125, Loss=1.8290 \n",
            "Epoch 3/20, Iteration 2100/3125, Loss=1.2901 \n",
            "Epoch 3/20, Iteration 2400/3125, Loss=0.9310 \n",
            "Epoch 3/20, Iteration 2700/3125, Loss=1.5093 \n",
            "Epoch 3/20, Iteration 3000/3125, Loss=1.0838 \n",
            "Epoch 4/20, Iteration 300/3125, Loss=1.2751 \n",
            "Epoch 4/20, Iteration 600/3125, Loss=1.5465 \n",
            "Epoch 4/20, Iteration 900/3125, Loss=1.2242 \n",
            "Epoch 4/20, Iteration 1200/3125, Loss=1.9551 \n",
            "Epoch 4/20, Iteration 1500/3125, Loss=1.3666 \n",
            "Epoch 4/20, Iteration 1800/3125, Loss=1.2914 \n",
            "Epoch 4/20, Iteration 2100/3125, Loss=1.3322 \n",
            "Epoch 4/20, Iteration 2400/3125, Loss=1.4400 \n",
            "Epoch 4/20, Iteration 2700/3125, Loss=1.6172 \n",
            "Epoch 4/20, Iteration 3000/3125, Loss=1.6088 \n",
            "Epoch 5/20, Iteration 300/3125, Loss=1.4668 \n",
            "Epoch 5/20, Iteration 600/3125, Loss=1.0628 \n",
            "Epoch 5/20, Iteration 900/3125, Loss=0.5771 \n",
            "Epoch 5/20, Iteration 1200/3125, Loss=1.3077 \n",
            "Epoch 5/20, Iteration 1500/3125, Loss=1.5106 \n",
            "Epoch 5/20, Iteration 1800/3125, Loss=1.4940 \n",
            "Epoch 5/20, Iteration 2100/3125, Loss=1.2606 \n",
            "Epoch 5/20, Iteration 2400/3125, Loss=1.4989 \n",
            "Epoch 5/20, Iteration 2700/3125, Loss=1.1820 \n",
            "Epoch 5/20, Iteration 3000/3125, Loss=1.3531 \n",
            "Epoch 6/20, Iteration 300/3125, Loss=1.4159 \n",
            "Epoch 6/20, Iteration 600/3125, Loss=1.2359 \n",
            "Epoch 6/20, Iteration 900/3125, Loss=1.3382 \n",
            "Epoch 6/20, Iteration 1200/3125, Loss=1.5110 \n",
            "Epoch 6/20, Iteration 1500/3125, Loss=1.3491 \n",
            "Epoch 6/20, Iteration 1800/3125, Loss=1.3816 \n",
            "Epoch 6/20, Iteration 2100/3125, Loss=1.2153 \n",
            "Epoch 6/20, Iteration 2400/3125, Loss=0.9222 \n",
            "Epoch 6/20, Iteration 2700/3125, Loss=0.9250 \n",
            "Epoch 6/20, Iteration 3000/3125, Loss=0.7539 \n",
            "Epoch 7/20, Iteration 300/3125, Loss=0.9267 \n",
            "Epoch 7/20, Iteration 600/3125, Loss=1.0232 \n",
            "Epoch 7/20, Iteration 900/3125, Loss=1.1882 \n",
            "Epoch 7/20, Iteration 1200/3125, Loss=1.1561 \n",
            "Epoch 7/20, Iteration 1500/3125, Loss=0.8748 \n",
            "Epoch 7/20, Iteration 1800/3125, Loss=0.8909 \n",
            "Epoch 7/20, Iteration 2100/3125, Loss=0.8548 \n",
            "Epoch 7/20, Iteration 2400/3125, Loss=1.1481 \n",
            "Epoch 7/20, Iteration 2700/3125, Loss=1.2690 \n",
            "Epoch 7/20, Iteration 3000/3125, Loss=1.3445 \n",
            "Epoch 8/20, Iteration 300/3125, Loss=1.1240 \n",
            "Epoch 8/20, Iteration 600/3125, Loss=1.1458 \n",
            "Epoch 8/20, Iteration 900/3125, Loss=1.5899 \n",
            "Epoch 8/20, Iteration 1200/3125, Loss=1.2886 \n",
            "Epoch 8/20, Iteration 1500/3125, Loss=0.9828 \n",
            "Epoch 8/20, Iteration 1800/3125, Loss=0.8912 \n",
            "Epoch 8/20, Iteration 2100/3125, Loss=0.6650 \n",
            "Epoch 8/20, Iteration 2400/3125, Loss=0.7620 \n",
            "Epoch 8/20, Iteration 2700/3125, Loss=1.0250 \n",
            "Epoch 8/20, Iteration 3000/3125, Loss=0.9513 \n",
            "Epoch 9/20, Iteration 300/3125, Loss=1.4169 \n",
            "Epoch 9/20, Iteration 600/3125, Loss=1.3282 \n",
            "Epoch 9/20, Iteration 900/3125, Loss=1.0779 \n",
            "Epoch 9/20, Iteration 1200/3125, Loss=0.8516 \n",
            "Epoch 9/20, Iteration 1500/3125, Loss=1.3454 \n",
            "Epoch 9/20, Iteration 1800/3125, Loss=1.4758 \n",
            "Epoch 9/20, Iteration 2100/3125, Loss=1.2549 \n",
            "Epoch 9/20, Iteration 2400/3125, Loss=1.1594 \n",
            "Epoch 9/20, Iteration 2700/3125, Loss=0.6812 \n",
            "Epoch 9/20, Iteration 3000/3125, Loss=1.6257 \n",
            "Epoch 10/20, Iteration 300/3125, Loss=1.1581 \n",
            "Epoch 10/20, Iteration 600/3125, Loss=1.0389 \n",
            "Epoch 10/20, Iteration 900/3125, Loss=1.2327 \n",
            "Epoch 10/20, Iteration 1200/3125, Loss=0.5085 \n",
            "Epoch 10/20, Iteration 1500/3125, Loss=1.0905 \n",
            "Epoch 10/20, Iteration 1800/3125, Loss=1.2277 \n",
            "Epoch 10/20, Iteration 2100/3125, Loss=0.8636 \n",
            "Epoch 10/20, Iteration 2400/3125, Loss=0.7291 \n",
            "Epoch 10/20, Iteration 2700/3125, Loss=1.1380 \n",
            "Epoch 10/20, Iteration 3000/3125, Loss=0.9376 \n",
            "Epoch 11/20, Iteration 300/3125, Loss=0.6121 \n",
            "Epoch 11/20, Iteration 600/3125, Loss=0.4400 \n",
            "Epoch 11/20, Iteration 900/3125, Loss=0.8957 \n",
            "Epoch 11/20, Iteration 1200/3125, Loss=0.6454 \n",
            "Epoch 11/20, Iteration 1500/3125, Loss=0.8330 \n",
            "Epoch 11/20, Iteration 1800/3125, Loss=0.7776 \n",
            "Epoch 11/20, Iteration 2100/3125, Loss=0.9975 \n",
            "Epoch 11/20, Iteration 2400/3125, Loss=0.9648 \n",
            "Epoch 11/20, Iteration 2700/3125, Loss=0.9803 \n",
            "Epoch 11/20, Iteration 3000/3125, Loss=1.2305 \n",
            "Epoch 12/20, Iteration 300/3125, Loss=1.4650 \n",
            "Epoch 12/20, Iteration 600/3125, Loss=1.0537 \n",
            "Epoch 12/20, Iteration 900/3125, Loss=0.8501 \n",
            "Epoch 12/20, Iteration 1200/3125, Loss=0.9600 \n",
            "Epoch 12/20, Iteration 1500/3125, Loss=1.3026 \n",
            "Epoch 12/20, Iteration 1800/3125, Loss=0.8193 \n",
            "Epoch 12/20, Iteration 2100/3125, Loss=0.7923 \n",
            "Epoch 12/20, Iteration 2400/3125, Loss=0.8659 \n",
            "Epoch 12/20, Iteration 2700/3125, Loss=1.0498 \n",
            "Epoch 12/20, Iteration 3000/3125, Loss=0.6970 \n",
            "Epoch 13/20, Iteration 300/3125, Loss=0.7324 \n",
            "Epoch 13/20, Iteration 600/3125, Loss=0.8705 \n",
            "Epoch 13/20, Iteration 900/3125, Loss=1.4076 \n",
            "Epoch 13/20, Iteration 1200/3125, Loss=0.7299 \n",
            "Epoch 13/20, Iteration 1500/3125, Loss=1.1730 \n",
            "Epoch 13/20, Iteration 1800/3125, Loss=0.6559 \n",
            "Epoch 13/20, Iteration 2100/3125, Loss=0.8290 \n",
            "Epoch 13/20, Iteration 2400/3125, Loss=0.4996 \n",
            "Epoch 13/20, Iteration 2700/3125, Loss=0.7197 \n",
            "Epoch 13/20, Iteration 3000/3125, Loss=0.9121 \n",
            "Epoch 14/20, Iteration 300/3125, Loss=1.1095 \n",
            "Epoch 14/20, Iteration 600/3125, Loss=0.8162 \n",
            "Epoch 14/20, Iteration 900/3125, Loss=0.6639 \n",
            "Epoch 14/20, Iteration 1200/3125, Loss=0.5094 \n",
            "Epoch 14/20, Iteration 1500/3125, Loss=0.5295 \n",
            "Epoch 14/20, Iteration 1800/3125, Loss=0.7803 \n",
            "Epoch 14/20, Iteration 2100/3125, Loss=0.7918 \n",
            "Epoch 14/20, Iteration 2400/3125, Loss=0.9925 \n",
            "Epoch 14/20, Iteration 2700/3125, Loss=1.3022 \n",
            "Epoch 14/20, Iteration 3000/3125, Loss=1.0947 \n",
            "Epoch 15/20, Iteration 300/3125, Loss=0.6843 \n",
            "Epoch 15/20, Iteration 600/3125, Loss=0.5320 \n",
            "Epoch 15/20, Iteration 900/3125, Loss=0.6625 \n",
            "Epoch 15/20, Iteration 1200/3125, Loss=0.6013 \n",
            "Epoch 15/20, Iteration 1500/3125, Loss=0.5590 \n",
            "Epoch 15/20, Iteration 1800/3125, Loss=0.7565 \n",
            "Epoch 15/20, Iteration 2100/3125, Loss=0.7868 \n",
            "Epoch 15/20, Iteration 2400/3125, Loss=1.0831 \n",
            "Epoch 15/20, Iteration 2700/3125, Loss=0.7432 \n",
            "Epoch 15/20, Iteration 3000/3125, Loss=1.0020 \n",
            "Epoch 16/20, Iteration 300/3125, Loss=0.8886 \n",
            "Epoch 16/20, Iteration 600/3125, Loss=0.3367 \n",
            "Epoch 16/20, Iteration 900/3125, Loss=0.6555 \n",
            "Epoch 16/20, Iteration 1200/3125, Loss=0.8472 \n",
            "Epoch 16/20, Iteration 1500/3125, Loss=0.6650 \n",
            "Epoch 16/20, Iteration 1800/3125, Loss=1.2790 \n",
            "Epoch 16/20, Iteration 2100/3125, Loss=0.8853 \n",
            "Epoch 16/20, Iteration 2400/3125, Loss=0.6871 \n",
            "Epoch 16/20, Iteration 2700/3125, Loss=0.6551 \n",
            "Epoch 16/20, Iteration 3000/3125, Loss=0.6140 \n",
            "Epoch 17/20, Iteration 300/3125, Loss=0.8485 \n",
            "Epoch 17/20, Iteration 600/3125, Loss=0.6001 \n",
            "Epoch 17/20, Iteration 900/3125, Loss=0.5482 \n",
            "Epoch 17/20, Iteration 1200/3125, Loss=0.6383 \n",
            "Epoch 17/20, Iteration 1500/3125, Loss=1.0393 \n",
            "Epoch 17/20, Iteration 1800/3125, Loss=0.8024 \n",
            "Epoch 17/20, Iteration 2100/3125, Loss=0.8803 \n",
            "Epoch 17/20, Iteration 2400/3125, Loss=0.9363 \n",
            "Epoch 17/20, Iteration 2700/3125, Loss=0.3155 \n",
            "Epoch 17/20, Iteration 3000/3125, Loss=1.1065 \n",
            "Epoch 18/20, Iteration 300/3125, Loss=0.6113 \n",
            "Epoch 18/20, Iteration 600/3125, Loss=0.5935 \n",
            "Epoch 18/20, Iteration 900/3125, Loss=0.9765 \n",
            "Epoch 18/20, Iteration 1200/3125, Loss=0.6887 \n",
            "Epoch 18/20, Iteration 1500/3125, Loss=0.9172 \n",
            "Epoch 18/20, Iteration 1800/3125, Loss=0.7588 \n",
            "Epoch 18/20, Iteration 2100/3125, Loss=0.7986 \n",
            "Epoch 18/20, Iteration 2400/3125, Loss=0.8072 \n",
            "Epoch 18/20, Iteration 2700/3125, Loss=0.7447 \n",
            "Epoch 18/20, Iteration 3000/3125, Loss=0.6836 \n",
            "Epoch 19/20, Iteration 300/3125, Loss=1.1985 \n",
            "Epoch 19/20, Iteration 600/3125, Loss=0.3357 \n",
            "Epoch 19/20, Iteration 900/3125, Loss=0.3808 \n",
            "Epoch 19/20, Iteration 1200/3125, Loss=0.3137 \n",
            "Epoch 19/20, Iteration 1500/3125, Loss=0.4358 \n",
            "Epoch 19/20, Iteration 1800/3125, Loss=0.7902 \n",
            "Epoch 19/20, Iteration 2100/3125, Loss=0.7446 \n",
            "Epoch 19/20, Iteration 2400/3125, Loss=0.5582 \n",
            "Epoch 19/20, Iteration 2700/3125, Loss=1.3958 \n",
            "Epoch 19/20, Iteration 3000/3125, Loss=0.2595 \n",
            "Epoch 20/20, Iteration 300/3125, Loss=0.5826 \n",
            "Epoch 20/20, Iteration 600/3125, Loss=1.0247 \n",
            "Epoch 20/20, Iteration 900/3125, Loss=0.5609 \n",
            "Epoch 20/20, Iteration 1200/3125, Loss=0.4512 \n",
            "Epoch 20/20, Iteration 1500/3125, Loss=0.5199 \n",
            "Epoch 20/20, Iteration 1800/3125, Loss=1.1120 \n",
            "Epoch 20/20, Iteration 2100/3125, Loss=0.7588 \n",
            "Epoch 20/20, Iteration 2400/3125, Loss=0.5310 \n",
            "Epoch 20/20, Iteration 2700/3125, Loss=0.5803 \n",
            "Epoch 20/20, Iteration 3000/3125, Loss=0.7804 \n",
            "Test Accuracy of the WHOLE CNN = 63.51 %\n",
            "Accuracy of plane: 75.5 %\n",
            "Accuracy of car: 76.6 %\n",
            "Accuracy of bird: 45.8 %\n",
            "Accuracy of cat: 45.9 %\n",
            "Accuracy of deer: 50.6 %\n",
            "Accuracy of dog: 56.4 %\n",
            "Accuracy of frog: 70.6 %\n",
            "Accuracy of horse: 72.1 %\n",
            "Accuracy of ship: 67.3 %\n",
            "Accuracy of truck: 74.3 %\n"
          ]
        }
      ]
    }
  ]
}
